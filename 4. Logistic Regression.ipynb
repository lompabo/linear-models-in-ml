{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload all imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Allow to pan and zoom graphs & charts\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Categorical Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Categorical Attributes\n",
    "\n",
    "**Let's switch to a different dataset (a toy one)**\n",
    "\n",
    "<center><img src=\"assets/weather.jpg\" style=\"height: 400px;\"></center>\n",
    "\n",
    "We want to train a model to choose whether to go out and play, based on weather conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loading the Data\n",
    "\n",
    "**The dataset is in the `weather.csv` files from the `data` folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_test.txt  lr_train.txt  real_estate.csv  weather.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temperature  humidity  windy play\n",
       "0     sunny           85        85  False   no\n",
       "1     sunny           80        90   True   no\n",
       "2  overcast           83        86  False  yes\n",
       "3     rainy           70        96  False  yes\n",
       "4     rainy           68        80  False  yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/weather.csv', sep=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Several attributes _do not have a numeric value_\n",
    "* Instead, their value is discrete with no clear ordering, i.e. _categorical_\n",
    "\n",
    "**We need a _numeric encoding_ to handle this data with linear models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Encoding Binary Attributes\n",
    "\n",
    "**Binary attributes can be encoded with the values 0 and 1**\n",
    "\n",
    "This is the case for the columns \"windy\" and \"play\"\n",
    "\n",
    "* First, we tell pandas that the columns have a categorical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: windy, dtype: category\n",
       "Categories (2, object): [False, True]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windy = data['windy'].astype('category')\n",
    "play = data['play'].astype('category')\n",
    "windy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Categorical data is still _displayed as a string_\n",
    "* ...But internally it is _encoded as an integer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Encoding Binary Attributes\n",
    "\n",
    "**Next, we replace the values with their integer code**\n",
    "\n",
    "We will store the results in a copy of the original table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temperature  humidity  windy  play\n",
       "0     sunny           85        85      0     0\n",
       "1     sunny           80        90      1     0\n",
       "2  overcast           83        86      0     1\n",
       "3     rainy           70        96      0     1\n",
       "4     rainy           68        80      0     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = data.copy() # We prepare a cop for the numeric encodings\n",
    "data2['windy'] = windy.cat.codes\n",
    "data2['play'] = play.cat.codes\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now it is apparent that \"windy\" and \"play\" have become numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Encoding Discrete Attributes\n",
    "\n",
    "**We could use the same approach for discrete attribute in general**\n",
    "\n",
    "E.g. for the attribute \"outlook\" in our table\n",
    "\n",
    "* That would yield a numeric _integer_ encoding\n",
    "* ...Which implies an ordering among the values (e.g. rainy < overcast < sunny)\n",
    "* When no such ranking exists, this is a bad idea\n",
    "\n",
    "**In these cases, it is better to adopt a one-hot encoding**\n",
    "\n",
    "* We introduce a column for each value $v_k$ of the attribute $xj$\n",
    "* The column contains a 1 iff $x_j = v_k$, and 0 otherwise\n",
    "* We remove the original attribute\n",
    "\n",
    "For example, \"sunny | sunny | overcast\" becomes:\n",
    "\n",
    "rainy | overcast | sunny\n",
    ":----:|:--------:|:-----:\n",
    "  0   |    0     |   1\n",
    "  0   |    0     |   1\n",
    "  0   |    1     |   0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Encoding Discrete Attributes\n",
    "\n",
    "**We can obtain a one-hot encoding in pandas via the `get_dummies` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "      <th>outlook_overcast</th>\n",
       "      <th>outlook_rainy</th>\n",
       "      <th>outlook_sunny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature  humidity  windy  play  outlook_overcast  outlook_rainy  \\\n",
       "0           85        85      0     0                 0              0   \n",
       "1           80        90      1     0                 0              0   \n",
       "2           83        86      0     1                 1              0   \n",
       "3           70        96      0     1                 0              1   \n",
       "4           68        80      0     1                 0              1   \n",
       "\n",
       "   outlook_sunny  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.get_dummies(data2)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The method by default processes all columns with categorical or object type\n",
    "* strings in csv files are often parsed as \"object\" columns\n",
    "* In truth, `get_dummies` can also handle the special case of binary variables\n",
    "* ...But I wanted to show you how to obtain an integer encoding, too :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "**Our goal is to predict the value of \"play\", i.e. _a categorical attribute_**\n",
    "\n",
    "Hence, we are dealing with _a classification problem_ and we need to make a few changes \n",
    "\n",
    "* We compute the output of the linear model as usual:\n",
    "$$\n",
    "g(x; w) = \\sum_{j=1} w_j x_j + w_0\n",
    "$$ \n",
    "* Then we feed it to a _logistic function_:\n",
    "$$\n",
    "f(x; w) = \\frac{1}{1 + e^{-g(x; w)}}\n",
    "$$\n",
    "\n",
    "**Note that here:**\n",
    "\n",
    "* The basis functions are $\\phi_j(x) = x_j$\n",
    "* There is an extra basis function $\\phi_0(x) = 1$ for the offset\n",
    "* This transformation can always be performed via a precomputation step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "**The logistic function is a type of _sigmoid_ function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082ea9bd990346d6b9b8dd05ee1936dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.plot(x, 1 / (1 + np.exp(-x)))\n",
    "plt.grid(':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Due to its use, this approach is known as _logistic regression_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "**Why using the logistic function?**\n",
    "\n",
    "* We can view the model output as a probability distribution\n",
    "* Specifically, as the probability of the class being \"1\"\n",
    "\n",
    "With this convention, the target can also be interpreted as a probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: play, dtype: int8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['play'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We view:\n",
    "\n",
    "* $y_i = 0$ as \"the probability of the class being 1 is equal to 0\"\n",
    "* $y_i = 1$ as \"the probability of the class being 1 is equal to 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Likelihood Function\n",
    "\n",
    "**We now assume that our model $f(x; w)$ is _the source of our data_**\n",
    "\n",
    "* When we see $y_i = 1$, we view it as \"the model has generated a 1\"\n",
    "* When we see $y_i = 0$, we view it as \"the model has generated a 0\"\n",
    "\n",
    "\n",
    "**With this, we can estimate _the probability of generating our data_**\n",
    "\n",
    "This is given by the probability of:\n",
    "\n",
    "* ...generating a 1 for all examples where the class is 1:\n",
    "$$\n",
    "\\prod_{y_i=1} f(x_i; w)\n",
    "$$\n",
    "* ...times that of generating a 0 for all examples where the class is 0:\n",
    "$$\n",
    "\\prod_{y_i=0} (1-f(x_i; w))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Likelihood Function\n",
    "\n",
    "**Overall, for a given dataset we get:**\n",
    "\n",
    "$$\n",
    "L(w) = \\prod_{y_i=1} f(x_i; w) \\prod_{y_i=0} (1-f(x_i; w))\n",
    "$$\n",
    "\n",
    "* The function is akin to a probability, but is _associated to our model_, not to the data itself\n",
    "* ...And in fact _depends on the parameters $w$_\n",
    "\n",
    "To make the distinction clearer, we call it a _likelihood function_\n",
    "\n",
    "**The likelihood is typically expressed in log form**\n",
    "\n",
    "$$\n",
    "\\log L(w) = \\sum_{i=1}^m y_i \\log f(x_i; w) + (1-y_i) \\log (1 - f(x; w))\n",
    "$$\n",
    "\n",
    "This expression happens to be the negative of the [_binary cross-entropy_](https://en.wikipedia.org/wiki/Cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Maximum Likelihood Estimation\n",
    "\n",
    "**Why is this relevant?**\n",
    "\n",
    "We want to train a model that is a _likely source for our data_\n",
    "\n",
    "* This means that we can choose the weights by solving:\n",
    "$$\n",
    "\\text{argmax}_w \\log L(w)\n",
    "$$\n",
    "* I.e. to _maximize the likelihood_ of the data\n",
    "\n",
    "With change of sign we get the equivalent formulation:\n",
    "$$\n",
    "\\text{argmin}_w - \\log L(w)\n",
    "$$\n",
    "* I.e. we want to _minimize the binary cross-entropy_\n",
    "* ...Meaning that the cross-entropy is going to be our _loss function_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Maximum Likelihood Estimation\n",
    "\n",
    "**MLE is very important in many Machine Learning approaches**\n",
    "\n",
    "* It provides an mathematical foundation and intuition for the training process\n",
    "  - I.e. we want to obtain a model the could plausibly be a source of the data\n",
    "* It applies to linear regression, too!\n",
    "  - The MSE is mapped 1-1 to a likelihood function...\n",
    "  - ...Assuming additive, Gaussian, noise with uniform variance\n",
    "\n",
    "**How do we solve the training problem?**\n",
    "\n",
    "$$\n",
    "\\text{argmin}_w - \\log L(w)\n",
    "$$\n",
    "\n",
    "* We can no longer reduce it to a system of linear equations\n",
    "* ...But it still has a unique minimizer!\n",
    "\n",
    "So it can be solved (e.g.) via gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Using Logistic Regression\n",
    "\n",
    "**Using Logistic Regression in scikit-learn is actually easy**\n",
    "\n",
    "We begin by splitting input/output data as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: play, dtype: int8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_in = [c for c in data2.columns if c != 'play']\n",
    "\n",
    "X = data2[cols_in]\n",
    "y = data2['play']\n",
    "y.head() # We have a table here, but a vector would also work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the training and test set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.34, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Using Logistic Regression\n",
    "\n",
    "**Then, we build a `LogisticRegression` model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "m = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...And we call the `fit` method as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(X_tr, y_tr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can obtain out predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tr = m.predict(X_tr)\n",
    "y_pred_ts = m.predict(X_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Better Look at the Predictions\n",
    "\n",
    "**By default, the prediction is the class with the largest probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 0, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we are interested in the raw probability values...\n",
    "* ...We can call the `predict_proba` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.726788  , 0.273212  ],\n",
       "       [0.3675285 , 0.6324715 ],\n",
       "       [0.77878844, 0.22121156],\n",
       "       [0.77593317, 0.22406683],\n",
       "       [0.48442042, 0.51557958]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob_tr = m.predict_proba(X_tr)\n",
    "y_prob_tr[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scikit-learn gives us the predicted probability of both classes\n",
    "* Hence, we get two separate columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "**We can evaluate the results using metrics**\n",
    "\n",
    "There are four basic metrics for binary classification:\n",
    "\n",
    "* Number of _True Positives_, i.e. $\\mathit{TP} = \\sum_{y_i=1} \\tilde{f}(x_i; w)$\n",
    "* Number of _True Negatives_, i.e. $\\mathit{TN} = \\sum_{y_i=0} (1 - \\tilde{f}(x_i; w))$\n",
    "* Number of _False Positives_, i.e. $\\mathit{FP} = \\sum_{y_i=0} \\tilde{f}(x_i; w)$\n",
    "* Number of _False Negatives_, i.e. $\\mathit{FN} = \\sum_{y_i=1} (1 - \\tilde{f}(x_i; w))$\n",
    "\n",
    "In all cases $\\tilde{f}(x_i; w)$ is the most probable class for the example $x_i$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "**From these we can derive a few more complex metrics**\n",
    "\n",
    "The model (binary) _accuracy_ is defined as:\n",
    "$$\n",
    "\\mathit{ACC} = \\frac{TP + TN}{m}\n",
    "$$\n",
    "* I.e. the fraction of examples that is _correctly classified_\n",
    "* The accuracy ranges over the interval $[0, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 0.778\n",
      "Accuracy on the test set: 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Accuracy on the training set: {accuracy_score(y_tr, y_pred_tr):.3}')\n",
    "print(f'Accuracy on the test set: {accuracy_score(y_ts, y_pred_ts):.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "**From these we can derive a few more complex metrics**\n",
    "\n",
    "The $F_1$ score is given by:\n",
    "$$\n",
    "\\mathit{F1} = \\frac{TP}{TP + \\frac{1}{2}(FP+FN)}\n",
    "$$\n",
    "* The F1 score ranges in the interval $[0, 1]$\n",
    "* F1 = 1 iff all positives are found and no negative is misclassified\n",
    "* F1 = 0 iff no positive is correctly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on the training set: 0.75\n",
      "F1 on the training set: 0.889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f'F1 on the training set: {f1_score(y_tr, y_pred_tr):.3}')\n",
    "print(f'F1 on the training set: {f1_score(y_ts, y_pred_ts):.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "**...Or we can plot all basic metrics via a _confusion matrix_**\n",
    "\n",
    "Here's the one for the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2315f97584440f6a5a0138c8cd207f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(m, X_tr, y_tr, display_labels=play.cat.categories, cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "**...Or we can plot all basic metrics via a _confusion matrix_**\n",
    "\n",
    "...And here for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b579ae86b30143cc9a81dd7aae1e3472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(m, X_ts, y_ts, display_labels=play.cat.categories, cmap='Blues');"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "rise": {
   "center": false,
   "transition": "fade"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
