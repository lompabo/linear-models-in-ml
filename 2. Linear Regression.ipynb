{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Automatically reload all imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Allow to pan and zoom graphs & charts\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Noise and Consequences\n",
    "\n",
    "**Let's go back to our asteroid example**\n",
    "\n",
    "<center><img src=\"assets/oumuamua.jpg\" style=\"height: 380px;\"></center>\n",
    "\n",
    "* What if our observations are _noisy_..\n",
    "* I.e. subject to measurement errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Noise and Consequences\n",
    "\n",
    "**Let us assume, that due to measurement errors:**\n",
    "\n",
    "* We should have observed $(0.5, 0.1), (-0.55, 0.5)$\n",
    "* ...But we instead observe $(0.53, 0.1), (-0.52, 0.5)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.55444973],\n",
       "       [0.15550718]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame(columns=['x0', 'x1'], data=[[0.53, 0.1], [-0.52, -0.5]])\n",
    "data\n",
    "\n",
    "A = data**2 # The table with\n",
    "b = np.ones((2, 1))\n",
    "\n",
    "w = np.linalg.solve(A, b)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Due the noise, our coefficients will be off\n",
    "* Even this small perturbation is enough for us to misclassify the curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## More Observations\n",
    "\n",
    "**One natural way to deal with this is using _more observations_**\n",
    "\n",
    "<center><img src=\"assets/trajectory.png\" style=\"height: 450px;\"></center>\n",
    "\n",
    "* Intuitively, the additional data compensates for measurement errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## More Observations\n",
    "\n",
    "**Say we have one additional data point**\n",
    "\n",
    "* Namely our \"revised\" observations $(x_{0,0}, x_{0,1}) = (0.53, 0.1)$, and $(x_{1,0}, x_{1,1}) = (-0.52, -0.5)$\n",
    "* ...Plus the point $(x_{2,0}, x_{2,1}) = (-0.7, -0.52)$\n",
    "\n",
    "**What happens to our system of linear equations?**\n",
    "\n",
    "$$\\begin{align}\n",
    "a x_{0,0}^2 + b x_{0,1}^2 &= 1 \\\\\n",
    "a x_{1,0}^2 + b x_{1,1}^2 &= 1 \\\\\n",
    "a x_{2,0}^2 + b x_{2,1}^2 &= 1 \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "* There are 3 equations (constraints) and 2 variables (degrees of freedom)\n",
    "* The system is _overdetermined_ (and impossible to solve exactly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Curve Fitting\n",
    "\n",
    "**However, we can go for an _approximate solution_**\n",
    "\n",
    "* Given a function $f(x,; w)$ with input $x$ and parameters $w$\n",
    "* ...And a dataset of observations $\\{x_i, y_i\\}_{i=1..m}$\n",
    "\n",
    "...We can define its approximation error over the observations\n",
    "\n",
    "$$\n",
    "\\mathit{MSE}(w) = \\sum_{i=1}^m \\left(f(x_i,; w) - y_i\\right)^2\n",
    "$$\n",
    "\n",
    "* \"MSE\" stands for _Mean Squared Error_ and it's a common error metric\n",
    "\n",
    "**Curve fitting**\n",
    "\n",
    "Consider the problem:\n",
    "\n",
    "$$\n",
    "\\text{argmin}_w \\, \\mathit{MSE}(w)\n",
    "$$\n",
    "\n",
    "\n",
    "* I.e. the problem of choosing weights/parameters $w$ to minimize approximation error\n",
    "* ...This is is sometimes referred to as _curve fitting_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Curve Fitting ...And Linear Regression\n",
    "\n",
    "**Linear Regression**\n",
    "\n",
    "When $f$ is defined as a _linear combination of basis functions_...\n",
    "\n",
    "$$\n",
    "f(x; w) = \\sum_{i=1}^n w_j \\phi_j(x)\n",
    "$$\n",
    "\n",
    "...The problem is called _linear regression_\n",
    "\n",
    "* It's called \"regression\" because we are estimating a numeric quantity\n",
    "* It's called \"linear\" because $f$ is linear w.r.t. its parameter vector $w$\n",
    "* The dataset used for minimization is usually called a _training set_\n",
    "* Note: the basis functions do not need to be linear!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Linear Least Squares Method\n",
    "\n",
    "**How do we solve it?**\n",
    "\n",
    "* It can be proved that the linear regression problem has _a unique minimizer_\n",
    "* ...And we can find it by searching for a $w$ that results in a _null gradient_:\n",
    "$$\n",
    "\\nabla{\\mathit{MSE}(w)} = 0\n",
    "$$\n",
    "\n",
    "In the linear case, it can be proven this is true iff:\n",
    "\n",
    "$$\n",
    "(A^T A) w = A^T b\n",
    "$$\n",
    "\n",
    "where $A$ and $b$ are defined as in the exact interpolation case, i.e.:\n",
    "\n",
    "$$\n",
    "A =\n",
    "\\left(\\begin{array}{ccc}\n",
    "\\phi_1(x_1) & \\cdots & \\phi_n(x_n) \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "\\phi_1(x_m) & \\cdots & \\phi_n(x_m) \\\\\n",
    "\\end{array}\\right)\n",
    "\\quad\n",
    "b = \n",
    "\\left(\\begin{array}{c}\n",
    "y_1 \\\\\n",
    "\\vdots \\\\\n",
    "y_m \\\\\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "**This is called the Linear Least Squares method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Linear Least Squares Method\n",
    "\n",
    "**Let's test it on the asteroid data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame(columns=['x0', 'x1'], data=[[0.53, 0.1], [-0.52, -0.5], [-0.7, -0.52]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First we build $A$ and $b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2704</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.2704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x0      x1\n",
       "0  0.2809  0.0100\n",
       "1  0.2704  0.2500\n",
       "2  0.4900  0.2704"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = data**2 # The table with\n",
    "b = np.ones((3, 1))\n",
    "display(A)\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Linear Least Squares Method\n",
    "\n",
    "* Then we can build $A^\\prime = A^TA$ and $b^\\prime = A^T b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aprime = np.matmul(A.values.T, A.values)\n",
    "bprime = np.matmul(A.values.T, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, we solve the modified system of linear equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.79747883],\n",
       "       [-0.27426684]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.linalg.solve(Aprime, bprime)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The opposite signs tell use this is one again a hyperbola\n",
    "* The approach works with any number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Linear Regression in Scikit-Learn\n",
    "\n",
    "**We can simplify the process by relying on external libraries**\n",
    "\n",
    "A nice implementation of Linear Regression is available from [scikit-learn](https://scikit-learn.org/)\n",
    "\n",
    "* We start by building a `LinearRegression` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "m = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The we obtain the parameters of the linear combination by calling the `fit` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we don't pass `fit_intercept=False`, the library will also calibrate an offset\n",
    "* We can then access the parameter values by accessing the `coef_` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.79747883, -0.27426684]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression - An Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Linear Regression - An Example\n",
    "\n",
    "**Our asteroid example was quite unusual**\n",
    "\n",
    "* Typically, linear regression is employed to estimate an unknown quantity\n",
    "* ...Based on the values of a number of available observations\n",
    "\n",
    "**We will see an example on [estimating the price of houses in Taiwan](https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set)**\n",
    "\n",
    "<center><img src=\"assets/taiwan-tea-house.jpg\" style=\"height: 400px;\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loading the Data\n",
    "\n",
    "**The dataset is available (in csv format) from the `data` folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_test.txt  lr_train.txt  real_estate.csv  weather.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will use pandas to load the csv dataset for the white wine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house age</th>\n",
       "      <th>dist to MRT</th>\n",
       "      <th>#stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price per area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>84.87882</td>\n",
       "      <td>10</td>\n",
       "      <td>24.98298</td>\n",
       "      <td>121.54024</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.5</td>\n",
       "      <td>306.59470</td>\n",
       "      <td>9</td>\n",
       "      <td>24.98034</td>\n",
       "      <td>121.53951</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>390.56840</td>\n",
       "      <td>5</td>\n",
       "      <td>24.97937</td>\n",
       "      <td>121.54245</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   house age  dist to MRT  #stores  latitude  longitude  price per area\n",
       "0       32.0     84.87882       10  24.98298  121.54024            37.9\n",
       "1       19.5    306.59470        9  24.98034  121.53951            42.2\n",
       "2       13.3    561.98450        5  24.98746  121.54391            47.3\n",
       "3       13.3    561.98450        5  24.98746  121.54391            54.8\n",
       "4        5.0    390.56840        5  24.97937  121.54245            43.1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/real_estate.csv', sep=';')\n",
    "data.head() # Head returns the first 5 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our goal is to predict the value of the \"quality\" columns\n",
    "* As a model, we will consider _a linear combination of the other columns (plus offset)_\n",
    "* The basis functions are linear, too: this is the most common case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Separating Input and Ouput\n",
    "\n",
    "**First, we separate our input and output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house age</th>\n",
       "      <th>dist to MRT</th>\n",
       "      <th>#stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>84.87882</td>\n",
       "      <td>10</td>\n",
       "      <td>24.98298</td>\n",
       "      <td>121.54024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.5</td>\n",
       "      <td>306.59470</td>\n",
       "      <td>9</td>\n",
       "      <td>24.98034</td>\n",
       "      <td>121.53951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>390.56840</td>\n",
       "      <td>5</td>\n",
       "      <td>24.97937</td>\n",
       "      <td>121.54245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   house age  dist to MRT  #stores  latitude  longitude\n",
       "0       32.0     84.87882       10  24.98298  121.54024\n",
       "1       19.5    306.59470        9  24.98034  121.53951\n",
       "2       13.3    561.98450        5  24.98746  121.54391\n",
       "3       13.3    561.98450        5  24.98746  121.54391\n",
       "4        5.0    390.56840        5  24.97937  121.54245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = data.columns\n",
    "X = data[cols[:-1]] # all columns except the last one\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will focus on predicting the logarithm (order of magnitude) of the price per area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(data[cols[-1]]) # just the last column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The $y$ values are often referred to as _targets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training and Test Set\n",
    "\n",
    "**Next, we remove part of the dataset: we will use it for testing**\n",
    "\n",
    "* This is called the _test set_ (use only for testing)\n",
    "* The remaining data will form the _training set_ (use for calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training set: 273\n",
      "Size of the test set: 141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.34, random_state=0)\n",
    "\n",
    "print(f'Size of the training set: {len(X_tr)}')\n",
    "print(f'Size of the test set: {len(X_ts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `train_test_split`\n",
    "\n",
    "* Randomly shuffles the data (optionally with a fixed seed `random_state`)\n",
    "* Puts a fraction `test_size` of the data in the test set\n",
    "* ...And the remaining data in the training set\n",
    "* Both the input and the output data is processed in this fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fitting the Model\n",
    "\n",
    "**We can now fit a linear model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LinearRegression()\n",
    "m.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the estimated output via the `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tr = m.predict(X_tr)\n",
    "y_pred_ts = m.predict(X_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The predictions (unlike the targets) are not guaranteed to be integers\n",
    "* ...But that is still fine, since it's easy to interpret them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "**Finally, we need to evaluate the prediction quality**\n",
    "\n",
    "A common approach is using metrics. Here are a few examples:\n",
    "\n",
    "* The _Mean Absolute Error_ is given by:\n",
    "$$\n",
    "\\mathit{MAE} = \\frac{1}{m}\\sum_{i=1}^m \\left|f(x_i) - y_i\\right|\n",
    "$$\n",
    "* The _Root Mean Squared Error_ is given by:\n",
    "$$\n",
    "\\mathit{RMSE} = \\sqrt{\\frac{1}{m} \\sum_{i=1}^m (f(x_i) - y_i)^2}\n",
    "$$\n",
    "\n",
    "Both the RMSE and MAE a simple error measures\n",
    "\n",
    "* They are expresses in the same unit as the original variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "\n",
    "* The coefficient of determination ($R^2$ coefficient) is given by:\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^m (f(x_i) - y_i)^2}{\\sum_{i=1}^m (y_i - \\tilde{y})^2}\n",
    "$$\n",
    "where $\\tilde{y}$ is the average of the $y$ values\n",
    "\n",
    "**The coefficient of determination is a useful, but more complex metric:**\n",
    "\n",
    "* Its maximum is 1: an $R^2 = 1$ implies perfect predictions\n",
    "* Having a known maximum make the metric very readable\n",
    "* It can be arbitrarily low (including negative)\n",
    "* It can be subject to a lot of noise if the targets $y$ have low variance\n",
    "\n",
    "**Using the MSE directly for evaluation is usually a bad idea**\n",
    "\n",
    "...Since it is a square, and therefore not easy to parse for a human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "**Let's see the values for our example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on the training data: 0.154\n",
      "MAE on the test data: 0.154\n",
      "RMSE on the training data: 0.214\n",
      "RMSE on the test data: 0.24\n",
      "R2 on the training data: 0.704\n",
      "R2 on the test data: 0.618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "print(f'MAE on the training data: {mean_absolute_error(y_tr, y_pred_tr):.3}')\n",
    "print(f'MAE on the test data: {mean_absolute_error(y_ts, y_pred_ts):.3}')\n",
    "print(f'RMSE on the training data: {np.sqrt(mean_squared_error(y_tr, y_pred_tr)):.3}')\n",
    "print(f'RMSE on the test data: {np.sqrt(mean_squared_error(y_ts, y_pred_ts)):.3}')\n",
    "print(f'R2 on the training data: {r2_score(y_tr, y_pred_tr):.3}')\n",
    "print(f'R2 on the test data: {r2_score(y_ts, y_pred_ts):.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In general, we have better predictions on the training set than on the test set\n",
    "* This is symptomatic of some _overfitting_\n",
    "* I.e. we are learning patterns in the training set that don't translate to unseen data\n",
    "\n",
    "Later on, we will see some techniques to deal with this situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "**As an (important!) alternative to metrics, we can use _scatter plots_:**\n",
    "\n",
    "* On the x-axis, we show the target values\n",
    "* On the y-axis, we show the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8dbf99e4b874c1aaa7c6fcd65860249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.scatter(y_ts, y_pred_ts, alpha=0.2)\n",
    "plt.plot(plt.xlim(), plt.ylim(), linestyle=':', color='0.5');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a better idea of which kind of mistakes the model is making"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "rise": {
   "center": false,
   "transition": "fade"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
